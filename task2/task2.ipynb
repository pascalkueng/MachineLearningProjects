{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import sklearn.metrics as metrics\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_unique_pids(featuresdf):\n",
    "    return featuresdf['pid'].unique()\n",
    "\n",
    "# aggregate data for all features\n",
    "def aggregate_all(featuresdf):\n",
    "    cc = featuresdf.groupby(['pid']).cumcount()+1\n",
    "    featuresdf = featuresdf.set_index(['pid', cc]).unstack()\n",
    "    featuresdf.columns = ['_'.join(map(str,i)) for i in featuresdf.columns]\n",
    "    featuresdf = featuresdf.reset_index()\n",
    "    multiples = ['Age']\n",
    "    vitals = ['Heartrate', 'SpO2', 'ABPs', 'ABPm', 'ABPd', 'RRate', 'Temp']\n",
    "    stats = ['mean', 'std', 'min', 'max']\n",
    "    for i in range(1,12):\n",
    "        stats.append('pct_' + str(i))\n",
    "    for vital in vitals:\n",
    "        for stat in stats:\n",
    "            multiples.append(vital + '_' + stat)\n",
    "    for multiple in multiples:\n",
    "        for i in range(2,13):\n",
    "            del featuresdf[multiple + '_' + str(i)]\n",
    "    return featuresdf\n",
    "\n",
    "def featureselect(featuresdf, featurenames):\n",
    "    pids = get_unique_pids(featuresdf)\n",
    "    featurenamesnr = []\n",
    "    for name in featurenames:\n",
    "        for i in range(1,13):\n",
    "            featurenamesnr.append(name + '_' + str(i))\n",
    "    newfeatures = pd.DataFrame(columns = featurenamesnr)\n",
    "    for pid in pids:\n",
    "        newfeatures = newfeatures.append(featuresdf.loc[featuresdf['pid'] == pid][featurenamesnr])\n",
    "    return newfeatures\n",
    "\n",
    "def calc_distribution(featuresdf):\n",
    "    means = pd.DataFrame()\n",
    "    stds = pd.DataFrame()\n",
    "    for column in featuresdf:\n",
    "        means[column] = 0\n",
    "        stds[column] = 0\n",
    "    pids = get_unique_pids(featuresdf)\n",
    "    for currentpid in pids:\n",
    "        currentfeatures = featuresdf.loc[featuresdf['pid'] == currentpid]\n",
    "        means = means.append(currentfeatures.mean(), ignore_index=True)\n",
    "        stds = stds.append(currentfeatures.std(), ignore_index=True)\n",
    "    means = means.mean()\n",
    "    stds = stds.mean()\n",
    "    return means, stds\n",
    "\n",
    "def impute(featuresdf, impute_strategy):\n",
    "    pids = get_unique_pids(featuresdf)\n",
    "    #means, stds = calc_distribution(featuresdf)\n",
    "    \n",
    "    featurenames = []\n",
    "    for column in featuresdf:\n",
    "        featurenames.append(column)\n",
    "    \n",
    "    medicalvalues = [-1, -1, -1, 40, 29, 16, 1.3, 37, 15, 24, 0, 15, 300, 3.5, 7, 0.75, 40, 26, 0.6, 275, 97, 100, 85, 1.7, 4.4, 70, 9.45, 80, 97.5, 0.1, 101, 45, 80, 0.5, 0.02, 105, 7.4]\n",
    "\n",
    "        \n",
    "    # interpolate for patients that have at least one value for that test\n",
    "    for currentpid in pids:\n",
    "        currentfeatures = featuresdf.loc[featuresdf['pid'] == currentpid]\n",
    "        featuresdf.loc[featuresdf['pid'] == currentpid] = currentfeatures.interpolate(limit_direction='both')\n",
    "    \n",
    "    # fill for patients without any value for that test\n",
    "    if(impute_strategy == 'random_mean'):\n",
    "        for column in featurenames:\n",
    "            featuresdf[column] = featuresdf[column].fillna(pd.Series([np.random.normal(means[column],stds[column]) for x in range(len(featuresdf))]))\n",
    "    elif (impute_strategy == 'mean'):\n",
    "        featuresdf = featuresdf.fillna(featuresdf.mean())\n",
    "    elif (impute_strategy == 'real'):\n",
    "        featuresdf = featuresdf.fillna((dict(zip(featuresdf.columns.tolist(), medicalvalues))))\n",
    "\n",
    "    \n",
    "    return featuresdf\n",
    "\n",
    "def normalize(featuresdf):\n",
    "    return pd.concat([featuresdf.iloc[:,:1],(featuresdf.iloc[:,1:]-featuresdf.iloc[:,1:].mean())/featuresdf.iloc[:,1:].std()], axis=1)\n",
    "     \n",
    "\n",
    "def split(featuresdf, labelsdf, ratio, randomized):\n",
    "    pids = get_unique_pids(featuresdf).tolist()\n",
    "    if(randomized):\n",
    "        shuffle(pids)\n",
    "    train_pids = pids[:int(ratio*len(pids))]\n",
    "    test_pids = pids[int(ratio*len(pids)):]\n",
    "    \n",
    "    X_train = featuresdf.iloc[0:0]\n",
    "    Y_train = labelsdf.iloc[0:0]\n",
    "    X_test = featuresdf.iloc[0:0]\n",
    "    Y_test = labelsdf.iloc[0:0]\n",
    "    \n",
    "    for pid in train_pids:\n",
    "        X_train = X_train.append(featuresdf.loc[featuresdf['pid'] == pid])\n",
    "        Y_train = Y_train.append(labelsdf.loc[labelsdf['pid'] == pid])\n",
    "        \n",
    "    for pid in test_pids:\n",
    "        X_test = X_test.append(featuresdf.loc[featuresdf['pid'] == pid])\n",
    "        Y_test = Y_test.append(labelsdf.loc[labelsdf['pid'] == pid])\n",
    "        \n",
    "    X_train = X_train.sort_values('pid')\n",
    "    Y_train = Y_train.sort_values('pid')\n",
    "    X_test = X_test.sort_values('pid')\n",
    "    Y_test = Y_test.sort_values('pid')\n",
    "\n",
    "    X_train = X_train.iloc[:,1:]\n",
    "    X_test = X_test.iloc[:,1:]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def medtest_features(featuresdf):\n",
    "    medicaltests = ['EtCO2', 'PTT', 'BUN', 'Lactate', 'Hgb', 'HCO3', 'BaseExcess', 'Fibrinogen', 'Phosphate', 'WBC', 'Creatinine', 'PaCO2', 'AST', 'FiO2', 'Platelets', 'SaO2', 'Glucose', 'Magnesium', 'Potassium', 'Calcium', 'Alkalinephos', 'Bilirubin_direct', 'Chloride', 'Hct', 'Bilirubin_total', 'TroponinI', 'pH']\n",
    "    \n",
    "    # add boolean value for each test as new feature\n",
    "    for medicaltest in medicaltests:\n",
    "        featuresdf[medicaltest + 'Test'] = featuresdf[medicaltest].notnull().astype('int')\n",
    "    \n",
    "    return featuresdf\n",
    "\n",
    "\n",
    "def vital_features(featuresdf):\n",
    "    vitals = ['Heartrate', 'SpO2', 'ABPs', 'ABPm', 'ABPd', 'RRate', 'Temp']\n",
    "    vitalvalues = [80, 97.5, 105, 85, 70, 15, 37]\n",
    "    for vital in vitals:\n",
    "        featuresdf[vital + '_mean'] = 0\n",
    "        featuresdf[vital + '_std'] = 0\n",
    "        featuresdf[vital + '_min'] = 0\n",
    "        featuresdf[vital + '_max'] = 0\n",
    "        for i in range(1,12):\n",
    "            featuresdf[vital + '_pct_' + str(i)] = 0\n",
    "    pids = get_unique_pids(featuresdf)\n",
    "    \n",
    "    for pid in pids:\n",
    "        currentfeatures = featuresdf.loc[featuresdf['pid'] == pid]\n",
    "        for vital in vitals:\n",
    "            featuresdf.loc[featuresdf['pid'] == pid, vital+'_mean'] = currentfeatures[vital].mean()\n",
    "            featuresdf.loc[featuresdf['pid'] == pid, vital+'_std'] = currentfeatures[vital].std()\n",
    "            featuresdf.loc[featuresdf['pid'] == pid, vital+'_min'] = currentfeatures[vital].min()\n",
    "            featuresdf.loc[featuresdf['pid'] == pid, vital+'_max'] = currentfeatures[vital].max()\n",
    "            for i in range(1,12):\n",
    "                featuresdf.loc[featuresdf['pid'] == pid, vital +'_pct_' + str(i)] = currentfeatures[vital].pct_change(fill_method='bfill').iloc[i]\n",
    "    \n",
    "    return featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Input\n",
    "max_patients = 18995\n",
    "num_patients = 18995\n",
    "features = pd.read_csv('train_features.csv', nrows=num_patients*12)\n",
    "labels = pd.read_csv('train_labels.csv', nrows=num_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.info()\n",
    "#features.describe()\n",
    "#features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_import = pd.read_csv('features_impreal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [ ],
   "source": [
    "#features_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_impreal = aggregate_all(normalize(vital_features(impute((medtest_features(features)), 'real'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_impreal.to_csv('features_impreal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = split(features_impreal, labels, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## TRAINING SUBTASK 1 ##\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ['BaseExcess', 'Fibrinogen', 'AST', 'Alkalinephos', 'Bilirubin_total', 'Lactate', 'TroponinI', 'SaO2', 'Bilirubin_direct', 'EtCO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_BaseExcess = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_BaseExcess)\n",
    "clf_Fibrinogen = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Fibrinogen)\n",
    "clf_AST = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_AST)\n",
    "clf_Alkalinephos = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Alkalinephos)\n",
    "clf_Bilirubin_total = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Bilirubin_total)\n",
    "clf_Lactate = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Lactate)\n",
    "clf_TroponinI = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_TroponinI)\n",
    "clf_SaO2 = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_SaO2)\n",
    "clf_Bilirubin_direct = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Bilirubin_direct)\n",
    "clf_EtCO2 = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_EtCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_BaseExcess = roc_auc_score(Y_test.LABEL_BaseExcess, clf_BaseExcess.predict_proba(X_test)[:,1])\n",
    "#roc_Fibrinogen = roc_auc_score(Y_test.LABEL_Fibrinogen, clf_Fibrinogen.predict_proba(X_test)[:,1])\n",
    "#roc_AST = roc_auc_score(Y_test.LABEL_AST, clf_AST.predict_proba(X_test)[:,1])\n",
    "#roc_Alkalinephos = roc_auc_score(Y_test.LABEL_Alkalinephos, clf_Alkalinephos.predict_proba(X_test)[:,1])\n",
    "#roc_Bilirubin_total = roc_auc_score(Y_test.LABEL_Bilirubin_total, clf_Bilirubin_total.predict_proba(X_test)[:,1])\n",
    "#roc_Lactate = roc_auc_score(Y_test.LABEL_Lactate, clf_Lactate.predict_proba(X_test)[:,1])\n",
    "#roc_TroponinI = roc_auc_score(Y_test.LABEL_TroponinI, clf_TroponinI.predict_proba(X_test)[:,1])\n",
    "#roc_SaO2 = roc_auc_score(Y_test.LABEL_SaO2, clf_SaO2.predict_proba(X_test)[:,1])\n",
    "#roc_Bilirubin_direct = roc_auc_score(Y_test.LABEL_Bilirubin_direct, clf_Bilirubin_direct.predict_proba(X_test)[:,1])\n",
    "#roc_EtCO2 = roc_auc_score(Y_test.LABEL_EtCO2, clf_EtCO2.predict_proba(X_test)[:,1])\n",
    "#print('BaseExcess: ' + str(roc_BaseExcess))\n",
    "#print('Fibrinogen: ' + str(roc_Fibrinogen))\n",
    "#print('AST: ' + str(roc_AST))\n",
    "#print('Alkalinephos: ' + str(roc_Alkalinephos))\n",
    "#print('Bilirubin_total: ' + str(roc_Bilirubin_total))\n",
    "#print('Lactate: ' + str(roc_Lactate))\n",
    "#print('TroponinI: ' + str(roc_TroponinI))\n",
    "#print('SaO2: ' + str(roc_SaO2))\n",
    "#print('Bilirubin_direct: ' + str(roc_Bilirubin_direct))\n",
    "#print('EtCO2: ' + str(roc_EtCO2))\n",
    "#print('Total: ' + str((roc_BaseExcess+roc_Fibrinogen+roc_AST+roc_Alkalinephos+roc_Bilirubin_total+roc_Lactate+roc_TroponinI+roc_SaO2+roc_Bilirubin_direct+roc_EtCO2)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## TRAINING SUBTASK 2 ##\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sepsis = RandomForestClassifier(n_estimators = 1000, min_samples_split = 12, min_samples_leaf = 7, max_features = 65, max_depth=90, bootstrap = False).fit(X_train,Y_train.LABEL_Sepsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## TRAINING SUBTASK 3 ##\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RRate = RandomForestRegressor(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_RRate)\n",
    "clf_ABPm = RandomForestRegressor(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_ABPm)\n",
    "clf_SpO2 = RandomForestRegressor(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_SpO2)\n",
    "clf_Heartrate = RandomForestRegressor(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth=100, bootstrap = False).fit(X_train,Y_train.LABEL_Heartrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_RRate = linear_model.Lasso(alpha=0.1, max_iter=10000).fit(X_train,Y_train.LABEL_RRate)\n",
    "#clf_ABPm = linear_model.Lasso(alpha=0.01, max_iter=10000).fit(X_train,Y_train.LABEL_ABPm)\n",
    "#clf_SpO2 = linear_model.Lasso(alpha=0.001, max_iter=10000).fit(X_train,Y_train.LABEL_SpO2)\n",
    "#clf_SpO2 = SVR().fit(X_train, Y_train.LABEL_SpO2)\n",
    "#clf_Heartrate = linear_model.Lasso(alpha=0.1, max_iter=10000).fit(X_train,Y_train.LABEL_Heartrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRate: 0.7161671383389238\n",
      "ABPm: 0.8078344537125959\n",
      "SpO2: 0.6883924506904575\n",
      "Heartrate: 0.823426938800143\n",
      "Total: 0.7589552453855299\n"
     ]
    }
   ],
   "source": [
    "#roc_RRate = 0.5 + 0.5 * np.maximum(0, metrics.r2_score(Y_test.LABEL_RRate, clf_RRate.predict(X_test)))\n",
    "#roc_ABPm = 0.5 + 0.5 * np.maximum(0, metrics.r2_score(Y_test.LABEL_ABPm, clf_ABPm.predict(X_test)))\n",
    "#roc_SpO2 = 0.5 + 0.5 * np.maximum(0, metrics.r2_score(Y_test.LABEL_SpO2, clf_SpO2.predict(X_test)))\n",
    "#roc_Heartrate = 0.5 + 0.5 * np.maximum(0, metrics.r2_score(Y_test.LABEL_Heartrate, clf_Heartrate.predict(X_test)))\n",
    "#print('RRate: ' + str(roc_RRate))\n",
    "#print('ABPm: ' + str(roc_ABPm))\n",
    "#print('SpO2: ' + str(roc_SpO2))\n",
    "#print('Heartrate: ' + str(roc_Heartrate))\n",
    "#print('Total: ' + str((roc_RRate+roc_ABPm+roc_SpO2+roc_Heartrate)/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "###############################\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## SUBMISSION ##\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('test_features.csv')\n",
    "submission = test_features[['pid']].iloc[::12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_impreal = aggregate_all(normalize(vital_features(impute((medtest_features(test_features)), 'real'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_impreal['pid'] = test_features_impreal['pid'].astype(str)\n",
    "test_features_impreal = test_features_impreal.sort_values('pid')\n",
    "test_features_impreal = test_features_impreal.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, Y_train, X_test, Y_test = split(features_impmean, labels, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions for test data and fill in submission\n",
    "submission['LABEL_BaseExcess'] = clf_BaseExcess.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Fibrinogen'] = clf_Fibrinogen.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_AST'] = clf_AST.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Alkalinephos'] = clf_Alkalinephos.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Bilirubin_total'] = clf_Bilirubin_total.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Lactate'] = clf_Lactate.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_TroponinI'] = clf_TroponinI.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_SaO2'] = clf_SaO2.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Bilirubin_direct'] = clf_Bilirubin_direct.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_EtCO2'] = clf_EtCO2.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_Sepsis'] = clf_sepsis.predict_proba(test_features_impreal)[:,1]\n",
    "submission['LABEL_RRate'] = clf_RRate.predict(test_features_impreal)\n",
    "submission['LABEL_ABPm'] = clf_ABPm.predict(test_features_impreal)\n",
    "submission['LABEL_SpO2'] = clf_SpO2.predict(test_features_impreal)\n",
    "submission['LABEL_Heartrate'] = clf_Heartrate.predict(test_features_impreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.zip', index=False, float_format='%.3f', compression=dict(method='zip', archive_name='submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
