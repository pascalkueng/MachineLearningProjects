{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IMPORTS #####\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Lambda, GlobalAveragePooling2D\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dir = 'food/'\n",
    "train_file = 'train_triplets.txt'\n",
    "test_file = 'test_triplets.txt'\n",
    "food_fnames = os.listdir(food_dir)\n",
    "print('total number of images: ', len(os.listdir(food_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SET PARAMETERS #####\n",
    "TRAIN_ROWS = 59515 # Max = 59515\n",
    "TEST_ROWS = 59544 # Max = 59544\n",
    "RATIO = 0.2\n",
    "RATIO_N_P = 0.3\n",
    "NR_OF_IMAGES = 10000 # Max = 10'000\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_COLORS = 3\n",
    "MARGIN = 0.3\n",
    "TRAIN_BATCH = 32\n",
    "TEST_BATCH = 72\n",
    "VALID_BATCH = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOCATION TO FILES #####\n",
    "FOOD_LOC = 'food/'\n",
    "TEST_LOC = 'test.txt'\n",
    "TRAIN_LOC = 'train.txt'\n",
    "TRAIN_TRIPLETS_LOC = 'train_triplets.txt'\n",
    "TEST_TRIPLETS_LOC = 'test_triplets.txt'\n",
    "SUBMISSION = 'submission.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HELPER FUNCTIONS #####\n",
    "\n",
    "# Returns the distances between the points\n",
    "def distance(a, p, n):\n",
    "  dist_a_p = tf.sqrt(tf.reduce_sum(tf.square(a - p), axis=1, keepdims=True))\n",
    "  dist_a_n = tf.sqrt(tf.reduce_sum(tf.square(a - n), axis=1, keepdims=True))\n",
    "  dist_p_n = tf.reduce_sum(tf.square(a - n), axis=1, keepdims=True)\n",
    "  return dist_a_p, dist_a_n, dist_p_n\n",
    "# Returns the loss function of our model\n",
    "def lossf(_, pred):\n",
    "  dist_a_p, dist_a_n, dist_p_n = distance(pred[:,0], pred[:,1], pred[:,2])\n",
    "  return tf.reduce_mean(tf.cast(tf.maximum(dist_a_p - (dist_a_n*(1-RATIO_N_P) + dist_p_n*RATIO_N_P) + MARGIN,0), tf.float32))\n",
    "# Accuracy function for our model\n",
    "def metrics(_, pred):\n",
    "  dist_a_p, dist_a_n, dist_p_n = distance(pred[:,0], pred[:,1], pred[:,2])\n",
    "  return tf.reduce_mean(tf.cast(tf.less_equal(dist_a_p, dist_a_n*(1-RATIO_N_P) + dist_p_n*RATIO_N_P), tf.float32))\n",
    "# Classification function for our model\n",
    "def classification(pred):\n",
    "  dist_a_p, dist_a_n, dist_p_n = distance(pred[:,0], pred[:,1], pred[:,2])\n",
    "  return tf.cast(tf.less_equal(dist_a_p, dist_a_n), tf.float32)\n",
    "# Counts the amount of rows in a file, i.e. amount of triplets\n",
    "def row_count(fname):\n",
    "  count = 0\n",
    "  with open(fname, 'r') as txtfile:\n",
    "    for line in txtfile:\n",
    "        count += 1\n",
    "  return count\n",
    "# Loads an image from the drive. Code from documentation but included image standardization and cast to our format\n",
    "def load_modify_image(jpg):\n",
    "  img = tf.io.read_file(FOOD_LOC + jpg + '.jpg')\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_COLORS)\n",
    "  img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
    "  img = preprocess_input(img)\n",
    "  return img\n",
    "# Loads the images for the corresponding triplet\n",
    "def load_triplet(triplet):\n",
    "  triplet = tf.strings.split(triplet)\n",
    "  return (load_modify_image(triplet[0]), \n",
    "          load_modify_image(triplet[1]), \n",
    "          load_modify_image(triplet[2])), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE TRAIN_TEST DATA #####\n",
    "# Important that the elements of these sets are disjoint to prevent overfitting\n",
    "with open(TRAIN_TRIPLETS_LOC, 'r') as fin, open(TRAIN_LOC, 'w') as train, open(TEST_LOC, 'w') as test:\n",
    "  rows = fin.readlines()    \n",
    "  tr_row, te_row = train_test_split(\n",
    "      list(dict.fromkeys([item for row in rows for item in row.split()])), \n",
    "      test_size=RATIO,\n",
    "      random_state = 2)\n",
    "  for row in rows:\n",
    "    triplets = row.split()\n",
    "    included_in_test = not bool(set(triplets) & set(te_row))\n",
    "    included_in_train = not bool(set(triplets) & set(tr_row))\n",
    "    if included_in_test or included_in_train:\n",
    "      if included_in_test:\n",
    "        train.write(row)\n",
    "      elif included_in_train:\n",
    "        test.write(row)\n",
    "# Print the sizes of the sets and their ratio\n",
    "ratio = np.round(row_count(TEST_LOC)/row_count(TRAIN_LOC)*100, 2)\n",
    "print(row_count(TEST_LOC), row_count(TRAIN_LOC))\n",
    "print(\"Ratio: \", ratio)\n",
    "# Get the numbers of steps for each dataset later\n",
    "steps_per_epoch = row_count(TRAIN_LOC) / float(TRAIN_BATCH)\n",
    "validation_steps = row_count(TEST_LOC) / float(VALID_BATCH)\n",
    "nr_test_steps = row_count(TEST_TRIPLETS_LOC)/float(TEST_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE DATASETS #####\n",
    "train_dataset = tf.data.TextLineDataset(TRAIN_LOC).map(load_triplet).shuffle(buffer_size=1000, seed = 2).repeat().batch(TRAIN_BATCH)\n",
    "validation_dataset = tf.data.TextLineDataset(TEST_LOC).map(load_triplet).repeat().batch(VALID_BATCH)\n",
    "test_dataset = tf.data.TextLineDataset(TEST_TRIPLETS_LOC).map(load_triplet).batch(TEST_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODEL #####\n",
    "base_model = InceptionV3(input_shape=(IMG_HEIGHT,IMG_WIDTH,IMG_COLORS), include_top=False)\n",
    "\n",
    "in_img_a = Input(shape=(IMG_HEIGHT,IMG_WIDTH,IMG_COLORS))\n",
    "in_img_p = Input(shape=(IMG_HEIGHT,IMG_WIDTH,IMG_COLORS))\n",
    "in_img_n = Input(shape=(IMG_HEIGHT,IMG_WIDTH,IMG_COLORS))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "func_vec_model = GlobalAveragePooling2D()(base_model.output)\n",
    "func_vec_model = Dropout(0.33)(func_vec_model)\n",
    "func_vec_model = Dense(256)(func_vec_model)\n",
    "func_vec_model = Lambda(lambda vect: tf.math.l2_normalize(vect, axis=1))(func_vec_model)\n",
    "\n",
    "jpg_enc = Model(base_model.input, func_vec_model)\n",
    "layer_out = Lambda(lambda vects: tf.stack(vects, axis=1))([jpg_enc(in_img_a), jpg_enc(in_img_p), jpg_enc(in_img_n)])\n",
    "model = Model((in_img_a, in_img_p, in_img_n), layer_out)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=lossf, metrics=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FIT MODEL ######\n",
    "model.fit(train_dataset,\n",
    "          steps_per_epoch=int(steps_per_epoch),\n",
    "          batch_size=TRAIN_BATCH,\n",
    "          epochs=1, \n",
    "          validation_data=validation_dataset,\n",
    "          validation_steps=int(validation_steps),\n",
    "          validation_batch_size=VALID_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MAKE PREDICTION #####\n",
    "full_model = Model(model.input, layers.Lambda(classification)(model.output))\n",
    "prediction = full_model.predict(test_dataset, verbose=1, steps=int(nr_test_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission_new.txt', prediction, fmt='%d')"
   ]
  }
 ]
}